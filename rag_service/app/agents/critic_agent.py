"""
Critic Agent - Ki·ªÉm tra hallucination v√† ch·∫•t l∆∞·ª£ng c√¢u tr·∫£ l·ªùi
"""
from typing import Dict, Any, Optional
import logging
from app.agents.base_agent import BaseAgent
from app.infrastructure.llm.openai import LLMProvider
from app.api.deps import get_llm_provider

logger = logging.getLogger(__name__)


class CriticAgent(BaseAgent):
    """
    Critic Agent ki·ªÉm tra:
    - Hallucination: C√¢u tr·∫£ l·ªùi c√≥ th√¥ng tin kh√¥ng c√≥ trong context kh√¥ng?
    - Accuracy: C√¢u tr·∫£ l·ªùi c√≥ ch√≠nh x√°c kh√¥ng?
    - Completeness: C√¢u tr·∫£ l·ªùi c√≥ ƒë·∫ßy ƒë·ªß kh√¥ng?
    - Relevance: C√¢u tr·∫£ l·ªùi c√≥ li√™n quan ƒë·∫øn c√¢u h·ªèi kh√¥ng?
    """
    
    def __init__(self, llm_provider: Optional[LLMProvider] = None):
        super().__init__("CriticAgent")
        self.llm_provider = llm_provider
    
    async def process(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        Ki·ªÉm tra ch·∫•t l∆∞·ª£ng c√¢u tr·∫£ l·ªùi
        
        Returns:
            Updated state with:
                - critic_score: ƒêi·ªÉm ƒë√°nh gi√° (0-1)
                - critic_feedback: Ph·∫£n h·ªìi t·ª´ critic
                - has_hallucination: C√≥ hallucination kh√¥ng?
                - final_answer_verified: C√¢u tr·∫£ l·ªùi ƒë√£ ƒë∆∞·ª£c verify
        """
        query = state.get("query", "").strip()
        final_answer = state.get("final_answer", "")
        knowledge_context = state.get("knowledge_context", "")
        tool_context = state.get("tool_context", "")
        reasoning_context = state.get("reasoning_context", "")
        
        # Lazy load LLM provider
        if not self.llm_provider:
            self.llm_provider = get_llm_provider()
        
        critic_score = 0.0
        critic_feedback = ""
        has_hallucination = False
        final_answer_verified = final_answer
        
        try:
            # T·∫°o critic prompt
            critic_prompt = self._create_critic_prompt(
                query=query,
                final_answer=final_answer,
                knowledge_context=knowledge_context,
                tool_context=tool_context,
                reasoning_context=reasoning_context
            )
            
            # G·ªçi LLM ƒë·ªÉ critic
            self.log("üîç Criticizing answer...")
            critic_result = await self.llm_provider.generate(
                prompt=critic_prompt,
                context="B·∫°n l√† Critic Agent trong h·ªá th·ªëng Multi-Agent RAG. Nhi·ªám v·ª• c·ªßa b·∫°n l√† ki·ªÉm tra ch·∫•t l∆∞·ª£ng c√¢u tr·∫£ l·ªùi, ph√°t hi·ªán hallucination v√† ƒë·∫£m b·∫£o t√≠nh ch√≠nh x√°c."
            )
            
            # Parse critic result
            critic_feedback = critic_result
            critic_score = self._extract_score(critic_result)
            has_hallucination = self._detect_hallucination(critic_result)
            
            # N·∫øu c√≥ hallucination, c·ªë g·∫Øng s·ª≠a
            if has_hallucination:
                self.log("‚ö†Ô∏è Hallucination detected, attempting to fix...")
                final_answer_verified = await self._fix_hallucination(
                    query=query,
                    original_answer=final_answer,
                    knowledge_context=knowledge_context,
                    tool_context=tool_context,
                    critic_feedback=critic_feedback
                )
            
            self.log(f"‚úÖ Critic completed (score: {critic_score:.2%}, hallucination: {has_hallucination})")
            
        except Exception as e:
            self.log(f"‚ùå Error in critic: {str(e)}", level="error")
            # Fallback: ch·∫•p nh·∫≠n c√¢u tr·∫£ l·ªùi g·ªëc
            critic_score = 0.7
            critic_feedback = "Kh√¥ng th·ªÉ ki·ªÉm tra chi ti·∫øt do l·ªói h·ªá th·ªëng"
            has_hallucination = False
            final_answer_verified = final_answer
        
        # C·∫≠p nh·∫≠t state
        state.update({
            "critic_score": critic_score,
            "critic_feedback": critic_feedback,
            "has_hallucination": has_hallucination,
            "final_answer_verified": final_answer_verified
        })
        
        return state
    
    def _create_critic_prompt(
        self,
        query: str,
        final_answer: str,
        knowledge_context: str,
        tool_context: str,
        reasoning_context: str
    ) -> str:
        """T·∫°o prompt cho critic"""
        prompt = f"""Ki·ªÉm tra ch·∫•t l∆∞·ª£ng c√¢u tr·∫£ l·ªùi sau:

C√¢u h·ªèi: {query}

C√¢u tr·∫£ l·ªùi:
{final_answer}

Th√¥ng tin c√≥ s·∫µn (context):
{knowledge_context if knowledge_context else "Kh√¥ng c√≥"}
{tool_context if tool_context else ""}
{reasoning_context if reasoning_context else ""}

H√£y ƒë√°nh gi√°:
1. Hallucination: C√¢u tr·∫£ l·ªùi c√≥ ch·ª©a th√¥ng tin KH√îNG c√≥ trong context kh√¥ng? (true/false)
2. Accuracy: C√¢u tr·∫£ l·ªùi c√≥ ch√≠nh x√°c d·ª±a tr√™n context kh√¥ng? (0-1)
3. Completeness: C√¢u tr·∫£ l·ªùi c√≥ ƒë·∫ßy ƒë·ªß kh√¥ng? (0-1)
4. Relevance: C√¢u tr·∫£ l·ªùi c√≥ li√™n quan ƒë·∫øn c√¢u h·ªèi kh√¥ng? (0-1)

Tr·∫£ l·ªùi theo format:
HALLUCINATION: true/false
ACCURACY: 0.0-1.0
COMPLETENESS: 0.0-1.0
RELEVANCE: 0.0-1.0
FEEDBACK: [Nh·∫≠n x√©t chi ti·∫øt]"""
        
        return prompt
    
    def _extract_score(self, critic_result: str) -> float:
        """Extract score t·ª´ critic result"""
        import re
        
        # T√¨m c√°c scores
        accuracy_match = re.search(r"ACCURACY:\s*([\d.]+)", critic_result, re.IGNORECASE)
        completeness_match = re.search(r"COMPLETENESS:\s*([\d.]+)", critic_result, re.IGNORECASE)
        relevance_match = re.search(r"RELEVANCE:\s*([\d.]+)", critic_result, re.IGNORECASE)
        
        scores = []
        if accuracy_match:
            scores.append(float(accuracy_match.group(1)))
        if completeness_match:
            scores.append(float(completeness_match.group(1)))
        if relevance_match:
            scores.append(float(relevance_match.group(1)))
        
        # Trung b√¨nh c√°c scores
        return sum(scores) / len(scores) if scores else 0.5
    
    def _detect_hallucination(self, critic_result: str) -> bool:
        """Ph√°t hi·ªán hallucination"""
        import re
        
        # T√¨m HALLUCINATION: true/false
        match = re.search(r"HALLUCINATION:\s*(true|false)", critic_result, re.IGNORECASE)
        if match:
            return match.group(1).lower() == "true"
        
        # Fallback: t√¨m t·ª´ kh√≥a
        if "hallucination" in critic_result.lower() and "true" in critic_result.lower():
            return True
        
        return False
    
    async def _fix_hallucination(
        self,
        query: str,
        original_answer: str,
        knowledge_context: str,
        tool_context: str,
        critic_feedback: str
    ) -> str:
        """S·ª≠a hallucination trong c√¢u tr·∫£ l·ªùi"""
        try:
            fix_prompt = f"""C√¢u tr·∫£ l·ªùi sau c√≥ ch·ª©a th√¥ng tin kh√¥ng ch√≠nh x√°c (hallucination). H√£y s·ª≠a l·∫°i ch·ªâ d·ª±a tr√™n th√¥ng tin c√≥ s·∫µn:

C√¢u h·ªèi: {query}

C√¢u tr·∫£ l·ªùi g·ªëc (c√≥ l·ªói):
{original_answer}

Th√¥ng tin c√≥ s·∫µn:
{knowledge_context if knowledge_context else "Kh√¥ng c√≥"}
{tool_context if tool_context else ""}

Ph·∫£n h·ªìi t·ª´ Critic:
{critic_feedback}

H√£y s·ª≠a l·∫°i c√¢u tr·∫£ l·ªùi, CH·ªà s·ª≠ d·ª•ng th√¥ng tin c√≥ trong context. N·∫øu kh√¥ng c√≥ ƒë·ªß th√¥ng tin, h√£y n√≥i r√µ."""
            
            fixed_answer = await self.llm_provider.generate(
                prompt=fix_prompt,
                context="B·∫°n ƒëang s·ª≠a c√¢u tr·∫£ l·ªùi c√≥ hallucination. Ch·ªâ s·ª≠ d·ª•ng th√¥ng tin c√≥ trong context."
            )
            
            return fixed_answer
            
        except Exception as e:
            self.log(f"Error fixing hallucination: {str(e)}", level="error")
            # Fallback: th√™m disclaimer
            return f"{original_answer}\n\n(L∆∞u √Ω: M·ªôt s·ªë th√¥ng tin c√≥ th·ªÉ ch∆∞a ƒë∆∞·ª£c x√°c minh)"

