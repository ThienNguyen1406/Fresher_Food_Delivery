"""
Knowledge Agent - RAG search t·ª´ vector store
"""
from typing import Dict, Any, List, Optional
import asyncio
import logging
from app.agents.base_agent import BaseAgent
from app.api.deps import get_image_vector_store, get_image_embedding_service, get_embedding_service
from app.infrastructure.vector_store.image_vector_store import ImageVectorStore
from app.services.image import ImageEmbeddingService
from app.services.embedding import EmbeddingService
from app.core.settings import Settings

logger = logging.getLogger(__name__)


class KnowledgeAgent(BaseAgent):
    """
    Knowledge Agent th·ª±c hi·ªán RAG search:
    - Text search: T·∫°o text embedding v√† search trong vector store
    - Image search: T·∫°o image embedding v√† search trong vector store
    - Hybrid search: K·∫øt h·ª£p c·∫£ hai
    """
    
    def __init__(
        self,
        vector_store: Optional[ImageVectorStore] = None,
        image_embedding_service: Optional[ImageEmbeddingService] = None,
        text_embedding_service: Optional[EmbeddingService] = None
    ):
        super().__init__("KnowledgeAgent")
        self.vector_store = vector_store
        self.image_embedding_service = image_embedding_service
        self.text_embedding_service = text_embedding_service
    
    async def process(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        Th·ª±c hi·ªán RAG search d·ª±a tr√™n query type
        """
        query_type = state.get("query_type", "text")
        query = state.get("query", "").strip()
        user_description = state.get("user_description", "")
        image_data = state.get("image_data")
        category_id = state.get("category_id")
        top_k = state.get("top_k", 5)
        
        # Lazy load services if not provided
        if not self.vector_store:
            self.vector_store = get_image_vector_store()
        if not self.image_embedding_service:
            self.image_embedding_service = get_image_embedding_service()
        if not self.text_embedding_service:
            self.text_embedding_service = get_embedding_service()
        
        knowledge_results = []
        knowledge_context = ""
        
        try:
            if query_type == "image" or query_type == "hybrid":
                # Image search
                if image_data:
                    self.log("üîç Performing image search...")
                    image_results = await self._search_by_image(
                        image_data=image_data,
                        category_id=category_id,
                        top_k=top_k
                    )
                    knowledge_results.extend(image_results)
            
            if query_type == "text" or query_type == "hybrid":
                # Text search
                search_text = query or user_description
                if search_text:
                    # üî• GI·∫¢I PH√ÅP 2: Normalize query - lo·∫°i b·ªè t·ª´ kh√≥a kh√¥ng li√™n quan ƒë·∫øn product
                    normalized_query = self._normalize_product_query_for_search(search_text)
                    self.log(f"üîç Performing text search: '{normalized_query}' (original: '{search_text}')...")
                    
                    # üî• FIX 2: Progressive fallback strategy
                    # Priority: SQL exact > SQL fuzzy > Vector search
                    sql_exact_results = await self._search_by_sql_exact_match(normalized_query, category_id, top_k)
                    text_results = []  # Initialize to avoid undefined error
                    
                    if sql_exact_results:
                        self.log(f"‚úÖ SQL exact match found: {len(sql_exact_results)} products. Using SQL results.")
                        knowledge_results.extend(sql_exact_results)
                    else:
                        # Try fuzzy SQL search
                        self.log(f"‚ö†Ô∏è SQL exact match found 0 results. Trying fuzzy SQL search...")
                        sql_fuzzy_results = await self._search_by_sql_fuzzy_match(normalized_query, category_id, top_k)
                        
                        if sql_fuzzy_results:
                            self.log(f"‚úÖ SQL fuzzy match found: {len(sql_fuzzy_results)} products. Using fuzzy SQL results.")
                            knowledge_results.extend(sql_fuzzy_results)
                        else:
                            # Last resort: vector search
                            self.log(f"‚ö†Ô∏è SQL fuzzy match found 0 results. Falling back to vector search...")
                            text_results = await self._search_by_text(
                                query=normalized_query,
                                category_id=category_id,
                                top_k=top_k
                            )
                            knowledge_results.extend(text_results)

                    
                    # üî• GI·∫¢I PH√ÅP 4: Fallback retry n·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c (ch·ªâ khi kh√¥ng c√≥ SQL results)
                    if not sql_exact_results and not text_results and search_text:
                        extracted_product = self._extract_product_name_from_query(search_text)
                        if extracted_product and extracted_product != normalized_query:
                            self.log(f"üîç Retrying search with extracted product name: '{extracted_product}'...")
                            retry_results = await self._search_by_text(
                                query=extracted_product,
                                category_id=category_id,
                                top_k=top_k
                            )
                            knowledge_results.extend(retry_results)
                            if retry_results:
                                self.log(f"‚úÖ Found {len(retry_results)} results with extracted product name")
            
            # Merge v√† deduplicate results
            knowledge_results = self._merge_results(knowledge_results)
            
            # ‚ö° FILTER: Ch·ªâ gi·ªØ l·∫°i results c√≥ similarity >= 0.5 (50%)
            SIMILARITY_THRESHOLD = 0.5
            similarity_filtered = [
                r for r in knowledge_results 
                if r.get("similarity", 0) >= SIMILARITY_THRESHOLD
            ]
            
            if len(similarity_filtered) < len(knowledge_results):
                self.log(f"‚ö†Ô∏è Filtered {len(knowledge_results) - len(similarity_filtered)} results with similarity < {SIMILARITY_THRESHOLD:.0%}")
            
            # üî• GI·∫¢I PH√ÅP 3: Lexical filter ch·ªâ ƒë·ªÉ rerank, kh√¥ng ph·∫£i gate
            # L∆∞u original vector results ƒë·ªÉ fallback n·∫øu lexical filter lo·∫°i h·∫øt
            original_vector_results = similarity_filtered.copy()
            filtered_results = similarity_filtered
            
            # üî• B·ªî SUNG: Ki·ªÉm tra keyword matching n·∫øu c√≥ query text (d√πng fuzzy match)
            # N·∫øu user h·ªèi "c√° h·ªìi" nh∆∞ng result l√† "th·ªãt b√≤" ‚Üí lo·∫°i b·ªè
            if query and filtered_results:
                query_lower = query.lower()
                # Extract keywords t·ª´ query (lo·∫°i b·ªè stopwords)
                import re
                from difflib import SequenceMatcher
                
                stopwords = {"h√¨nh", "·∫£nh", "h√¨nh ·∫£nh", "l·∫•y", "ra", "v√†", "c·ªßa", "n√≥", "theo", "th√°ng", "doanh", "thu", "s·ªë"}
                query_keywords = [w for w in re.sub(r'[^a-z√†-·ªπ\s]', ' ', query_lower).split() 
                                 if w and w not in stopwords and len(w) > 2]
                
                if query_keywords:
                    # üî• GI·∫¢I PH√ÅP 2: Whole-word matching + synonym + fuzzy match
                    truly_matched = []
                    for result in filtered_results:
                        product_name = result.get("product_name", "").lower()
                        
                        # Synonym map
                        synonym_map = {
                            "c√° h·ªìi": ["c√° h·ªìi", "salmon", "c√° h·ªìi na uy", "c√° h·ªìi t∆∞∆°i"],
                            "th·ªãt b√≤": ["th·ªãt b√≤", "beef", "th·ªãt b√≤ t∆∞∆°i"],
                            "th·ªãt heo": ["th·ªãt heo", "pork", "th·ªãt l·ª£n"],
                            "g√†": ["g√†", "chicken", "g√† ta"],
                            "t√¥m": ["t√¥m", "shrimp", "t√¥m s√∫"],
                        }
                        
                        # Ki·ªÉm tra match v·ªõi t·ª´ng keyword
                        matched = False
                        for keyword in query_keywords:
                            keyword_lower = keyword.lower()
                            
                            # 1. Whole-word exact match (quan tr·ªçng nh·∫•t)
                            import re
                            # Match whole word, kh√¥ng match substring
                            word_pattern = r'\b' + re.escape(keyword_lower) + r'\b'
                            if re.search(word_pattern, product_name):
                                matched = True
                                break
                            
                            # 2. Synonym match
                            for main_term, synonyms in synonym_map.items():
                                if keyword_lower in main_term or main_term in keyword_lower:
                                    # Check n·∫øu product_name ch·ª©a b·∫•t k·ª≥ synonym n√†o
                                    if any(re.search(r'\b' + re.escape(syn) + r'\b', product_name) for syn in synonyms):
                                        matched = True
                                        break
                                if matched:
                                    break
                            
                            if matched:
                                break
                            
                            # 3. Fuzzy match (cho ph√©p typo nh·ªè) - ch·ªâ khi kh√¥ng c√≥ exact/synonym match
                            if not matched and len(keyword_lower) >= 3:
                                product_words = product_name.split()
                                for word in product_words:
                                    if len(word) >= 3:
                                        similarity_ratio = SequenceMatcher(None, keyword_lower, word).ratio()
                                        if similarity_ratio > 0.7:  # 70% similarity
                                            matched = True
                                            break
                                if matched:
                                    break
                        
                        if matched:
                            truly_matched.append(result)
                        else:
                            self.log(f"‚ö†Ô∏è Filtered out product '{result.get('product_name')}' - kh√¥ng kh·ªõp keywords: {query_keywords}")
                    
                    if truly_matched:
                        filtered_results = truly_matched
                    else:
                        # üî• GI·∫¢I PH√ÅP 1: Fallback khi lexical filter lo·∫°i h·∫øt
                        # N·∫øu vector search ƒë√£ t√¨m ƒë∆∞·ª£c k·∫øt qu·∫£ c√≥ similarity cao, kh√¥ng n√™n lo·∫°i h·∫øt
                        self.log(f"‚ö†Ô∏è Lexical filter removed all results. Falling back to top vector results (similarity >= {SIMILARITY_THRESHOLD:.0%})")
                        # Tr·∫£ v·ªÅ top results t·ª´ vector search (ƒë√£ filter similarity)
                        filtered_results = original_vector_results[:5]  # Top 5 t·ª´ vector search
                        if filtered_results:
                            self.log(f"‚úÖ Fallback: Using {len(filtered_results)} top vector results")
            
            knowledge_results = filtered_results
            
            # Format context
            knowledge_context = self._format_context(knowledge_results)
            
            self.log(f"‚úÖ Found {len(knowledge_results)} knowledge results (after filtering)")
            
        except Exception as e:
            self.log(f"‚ùå Error in knowledge search: {str(e)}", level="error")
            knowledge_results = []
            knowledge_context = ""
        
        # C·∫≠p nh·∫≠t state
        state.update({
            "knowledge_results": knowledge_results,
            "knowledge_context": knowledge_context
        })
        
        return state
    
    async def _search_by_image(
        self,
        image_data: bytes,
        category_id: Optional[str] = None,
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """Search products by image"""
        try:
            # T·∫°o image embedding
            query_embedding = await self.image_embedding_service.create_embedding(image_data)
            
            if query_embedding is None:
                return []
            
            # Build where clause
            where_clause = {"content_type": "product"}
            if category_id:
                where_clause["category_id"] = category_id
            
            # Vector search
            results = await asyncio.to_thread(
                self.vector_store.collection.query,
                query_embeddings=[query_embedding.tolist()],
                n_results=top_k,
                where=where_clause
            )
            
            # Parse results
            products = []
            if results.get('ids') and len(results['ids'][0]) > 0:
                for i in range(len(results['ids'][0])):
                    metadata = results['metadatas'][0][i]
                    distance = results['distances'][0][i] if 'distances' in results and results['distances'] else 1.0
                    similarity = 1 - distance
                    
                    product = {
                        "product_id": metadata.get('file_id', '') or metadata.get('product_id', ''),
                        "product_name": metadata.get('product_name', ''),
                        "category_id": metadata.get('category_id', ''),
                        "category_name": metadata.get('category_name', ''),
                        "similarity": float(similarity),
                        "price": float(metadata.get('price', 0)) if metadata.get('price') else None,
                        "source": "image_search"
                    }
                    products.append(product)
            
            return products
            
        except Exception as e:
            self.log(f"Error in image search: {str(e)}", level="error")
            return []
    
    async def _search_by_text(
        self,
        query: str,
        category_id: Optional[str] = None,
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """Search products by text"""
        try:
            # T·∫°o text embedding (d√πng CLIP text encoder ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi image embeddings)
            query_embedding = self.image_embedding_service.create_text_embedding(query)
            
            if query_embedding is None:
                return []
            
            # Build where clause
            where_clause = {"content_type": "product"}
            if category_id:
                where_clause["category_id"] = category_id
            
            # Vector search
            results = await asyncio.to_thread(
                self.vector_store.collection.query,
                query_embeddings=[query_embedding.tolist()],
                n_results=top_k,
                where=where_clause
            )
            
            # Parse results
            products = []
            if results.get('ids') and len(results['ids'][0]) > 0:
                for i in range(len(results['ids'][0])):
                    metadata = results['metadatas'][0][i]
                    distance = results['distances'][0][i] if 'distances' in results and results['distances'] else 1.0
                    similarity = 1 - distance
                    
                    product = {
                        "product_id": metadata.get('file_id', '') or metadata.get('product_id', ''),
                        "product_name": metadata.get('product_name', ''),
                        "category_id": metadata.get('category_id', ''),
                        "category_name": metadata.get('category_name', ''),
                        "similarity": float(similarity),
                        "price": float(metadata.get('price', 0)) if metadata.get('price') else None,
                        "source": "text_search"
                    }
                    products.append(product)
            
            return products
            
        except Exception as e:
            self.log(f"Error in text search: {str(e)}", level="error")
            return []
    
    def _merge_results(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Merge v√† deduplicate results t·ª´ nhi·ªÅu sources"""
        seen = {}
        merged = []
        
        for result in results:
            product_id = result.get("product_id")
            if not product_id:
                continue
            
            # N·∫øu ƒë√£ c√≥, ch·ªçn result c√≥ similarity cao h∆°n
            if product_id in seen:
                existing = seen[product_id]
                if result.get("similarity", 0) > existing.get("similarity", 0):
                    seen[product_id] = result
            else:
                seen[product_id] = result
        
        # Sort by similarity
        merged = sorted(seen.values(), key=lambda x: x.get("similarity", 0), reverse=True)
        
        return merged
    
    def _normalize_product_query_for_search(self, query: str) -> str:
        """
        üî• GI·∫¢I PH√ÅP 2: Normalize query cho product search - lo·∫°i b·ªè t·ª´ kh√≥a kh√¥ng li√™n quan
        V√≠ d·ª•: "h√¨nh ·∫£nh c√° h·ªìi v√† doanh thu theo th√°ng" ‚Üí "c√° h·ªìi"
        M·ª•c ti√™u: Ch·ªâ gi·ªØ l·∫°i t√™n s·∫£n ph·∫©m ƒë·ªÉ vector embedding match t·ªët h∆°n
        """
        import re
        
        if not query:
            return query
        
        q = query.lower()
        
        # Lo·∫°i b·ªè t·ª´ kh√≥a nhi·ªÖu (noise words) - ∆∞u ti√™n lo·∫°i b·ªè c·ª•m t·ª´ tr∆∞·ªõc
        noise_phrases = [
            "h√¨nh ·∫£nh", "·∫£nh", "image", "picture",
            "doanh thu", "doanh s·ªë", "th·ªëng k√™", "theo th√°ng", 
            "b√°n ch·∫°y", "gi√° bao nhi√™u", "revenue", "sales",
            "l·∫•y ra", "l·∫•y", "hi·ªÉn th·ªã", "show", "display"
        ]
        
        # Lo·∫°i b·ªè c·ª•m t·ª´ tr∆∞·ªõc (ƒë·ªÉ tr√°nh "h√¨nh ·∫£nh" ‚Üí "h√¨nh" + "·∫£nh" c√≤n s√≥t)
        for phrase in noise_phrases:
            q = q.replace(phrase, " ")
        
        # Lo·∫°i b·ªè t·ª´ ƒë∆°n l·∫ª
        noise_words = [
            "v√†", "c·ªßa", "n√≥", "cho", "t·ª´", "ƒë·∫øn", "trong", "ngo√†i",
            "ra", "v·ªÅ", "v·ªõi", "nƒÉm", "th√°ng", "ng√†y"
        ]
        
        for word in noise_words:
            # Ch·ªâ replace n·∫øu l√† t·ª´ ƒë∆°n l·∫ª (c√≥ space xung quanh ho·∫∑c ƒë·∫ßu/cu·ªëi)
            q = re.sub(rf'\b{re.escape(word)}\b', ' ', q)
        
        # Clean up multiple spaces
        q = re.sub(r'\s+', ' ', q).strip()
        
        # N·∫øu normalized qu√° ng·∫Øn ho·∫∑c r·ªóng, d√πng query g·ªëc
        if len(q) < 2:
            q = query.strip()
        
        self.log(f"üîç Normalized query: '{q}' (from '{query}')")
        return q
    
    def _extract_product_name_from_query(self, query: str) -> Optional[str]:
        """
        Extract product name t·ª´ query ph·ª©c t·∫°p.
        V√≠ d·ª•: "h√¨nh ·∫£nh c√° h·ªìi v√† doanh thu theo th√°ng" ‚Üí "c√° h·ªìi"
        """
        import re
        
        # Lo·∫°i b·ªè c√°c t·ª´ kh√¥ng quan tr·ªçng (stopwords)
        stopwords = {
            "h√¨nh", "·∫£nh", "h√¨nh ·∫£nh", "hinh", "anh",
            "l·∫•y", "lay", "ra", "xem", "xem th·ª≠",
            "s·∫£n", "ph·∫©m", "san", "pham", "s·∫£n ph·∫©m",
            "c·ªßa", "v·ªÅ", "v·ªõi", "gi√∫p", "m√¨nh", "t√¥i",
            "v√†", "c≈©ng", "nh∆∞", "l√†", "c√≥", "kh√¥ng",
            "theo", "th√°ng", "doanh", "thu", "s·ªë", "th·ªëng", "k√™",
            "n√≥", "cho", "t·ª´", "ƒë·∫øn", "trong", "ngo√†i", "nƒÉm"
        }
        
        # Normalize query
        query_lower = query.lower()
        query_clean = re.sub(r'[^\w\s]', ' ', query_lower)
        words = [w for w in query_clean.split() if w and w not in stopwords and len(w) > 2]
        
        # üî• C·∫¢I THI·ªÜN: T√¨m c·ª•m t·ª´ ph·ªï bi·∫øn cho t√™n s·∫£n ph·∫©m th·ª±c ph·∫©m
        # V√≠ d·ª•: "c√° h·ªìi", "th·ªãt b√≤", "rau c·∫£i", "g√† n∆∞·ªõng"
        common_product_patterns = [
            r"c√°\s+\w+",  # "c√° h·ªìi", "c√° thu"
            r"th·ªãt\s+\w+",  # "th·ªãt b√≤", "th·ªãt heo"
            r"rau\s+\w+",  # "rau c·∫£i", "rau mu·ªëng"
            r"g√†\s+\w+",  # "g√† n∆∞·ªõng", "g√† r√°n"
            r"t√¥m\s+\w+",  # "t√¥m s√∫", "t√¥m h√πm"
            r"khoai\s+\w+",  
            r"n∆∞·ªõc\s+\w+",  
            r"s·ªØa\s+\w+",
        ]
        
        for pattern in common_product_patterns:
            match = re.search(pattern, query_lower)
            if match:
                extracted = match.group(0).strip()
                if len(extracted) >= 4:  # ƒê·∫£m b·∫£o ƒë·ªß d√†i
                    self.log(f"‚úÖ Extracted product name using pattern: '{extracted}'")
                    return extracted
        
        # N·∫øu kh√¥ng match pattern, th·ª≠ c·ª•m 2 t·ª´ li√™n ti·∫øp
        if len(words) >= 2:
            # Th·ª≠ c·ª•m 2 t·ª´ tr∆∞·ªõc (th∆∞·ªùng l√† t√™n s·∫£n ph·∫©m)
            for i in range(len(words) - 1):
                phrase = f"{words[i]} {words[i+1]}"
                if len(phrase) >= 4:  # ƒê·∫£m b·∫£o ƒë·ªß d√†i
                    self.log(f"‚úÖ Extracted product name: '{phrase}'")
                    return phrase
        elif len(words) == 1:
            self.log(f"‚úÖ Extracted product name (single word): '{words[0]}'")
            return words[0]
        
        # N·∫øu kh√¥ng extract ƒë∆∞·ª£c, tr·∫£ v·ªÅ None
        self.log(f"‚ö†Ô∏è Could not extract product name from query: '{query[:50]}'")
        return None
    
    def _format_context(self, results: List[Dict[str, Any]]) -> str:
        """Format search results th√†nh context string"""
        if not results:
            return ""
        
        context_parts = []
        for i, result in enumerate(results[:5], 1):  # Top 5 results
            product_name = result.get("product_name", "Unknown")
            category_name = result.get("category_name", "")
            price = result.get("price")
            similarity = result.get("similarity", 0)
            
            context = f"{i}. {product_name}"
            if category_name:
                context += f" (Danh m·ª•c: {category_name})"
            if price:
                context += f" - Gi√°: {price:,.0f} VND"
            context += f" (ƒê·ªô t∆∞∆°ng ƒë·ªìng: {similarity:.2%})"
            
            context_parts.append(context)
        
        return "\n".join(context_parts)
    
    async def _search_by_sql_exact_match(
        self,
        query: str,
        category_id: Optional[str] = None,
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """
        üî• FIX 2: SQL exact match TR∆Ø·ªöC vector search
        T√¨m s·∫£n ph·∫©m b·∫±ng SQL LIKE ƒë·ªÉ ƒë·∫£m b·∫£o entity match ch√≠nh x√°c
        """
        try:
            connection_string = Settings.DATABASE_CONNECTION_STRING
            if not connection_string:
                self.log("‚ö†Ô∏è DATABASE_CONNECTION_STRING not found. Skipping SQL exact match.")
                return []
            
            import pyodbc
            import asyncio
            
            # üî• FIX: Ki·ªÉm tra driver c√≥ s·∫µn kh√¥ng
            try:
                # Test connection tr∆∞·ªõc
                test_conn = pyodbc.connect(connection_string, timeout=2)
                test_conn.close()
            except pyodbc.Error as e:
                error_code = str(e)
                if "IM002" in error_code or "driver" in error_code.lower():
                    self.log(f"‚ö†Ô∏è ODBC Driver not found or connection failed: {error_code}. Skipping SQL exact match.")
                    return []
                raise
            
            # Extract keywords t·ª´ query ƒë·ªÉ search
            keywords = query.split()
            if not keywords:
                return []
            
            # Th·ª≠ search v·ªõi t·ª´ng keyword, ∆∞u ti√™n keyword d√†i nh·∫•t
            keywords_sorted = sorted(keywords, key=len, reverse=True)
            
            # üî• FIX: Chuy·ªÉn th√†nh sync function ƒë·ªÉ d√πng v·ªõi asyncio.to_thread
            def search_in_db():
                """Sync function ƒë·ªÉ ch·∫°y trong thread pool"""
                conn = None
                try:
                    conn = pyodbc.connect(connection_string)
                    cursor = conn.cursor()
                    
                    # Search v·ªõi keyword ƒë·∫ßu ti√™n (d√†i nh·∫•t)
                    keyword = keywords_sorted[0]
                    like_pattern = f"%{keyword}%"
                    
                    db_query = f"""
                        SELECT TOP {top_k}
                            s.MaSanPham,
                            s.TenSanPham,
                            s.MoTa,
                            s.Anh,
                            s.GiaBan,
                            s.DonViTinh,
                            s.MaDanhMuc,
                            dm.TenDanhMuc
                        FROM SanPham s
                        LEFT JOIN DanhMuc dm ON s.MaDanhMuc = dm.MaDanhMuc
                        WHERE (s.IsDeleted = 0 OR s.IsDeleted IS NULL)
                          AND s.TenSanPham LIKE ?
                        ORDER BY
                            CASE WHEN s.TenSanPham LIKE ? THEN 0 ELSE 1 END,
                            s.TenSanPham
                    """
                    
                    cursor.execute(db_query, like_pattern, like_pattern)
                    rows = cursor.fetchall()
                    
                    products = []
                    for row in rows:
                        product_id, product_name, description, image_filename, price, don_vi_tinh, cat_id, cat_name = row
                        
                        # üî• BONUS: Guardrail ch·ªëng nh·∫ßm s·∫£n ph·∫©m v·ªõi synonym + fuzzy match
                        product_name_lower = product_name.lower()
                        
                        # Synonym map cho c√°c s·∫£n ph·∫©m ph·ªï bi·∫øn
                        synonym_map = {
                            "c√° h·ªìi": ["c√° h·ªìi", "salmon", "c√° h·ªìi na uy", "c√° h·ªìi t∆∞∆°i"],
                            "th·ªãt b√≤": ["th·ªãt b√≤", "beef", "th·ªãt b√≤ t∆∞∆°i"],
                            "th·ªãt heo": ["th·ªãt heo", "pork", "th·ªãt l·ª£n"],
                            "g√†": ["g√†", "chicken", "g√† ta", "g√† c√¥ng nghi·ªáp"],
                            "t√¥m": ["t√¥m", "shrimp", "t√¥m s√∫", "t√¥m h√πm"],
                        }
                        
                        # Ki·ªÉm tra match v·ªõi synonym
                        matched = False
                        for keyword in keywords_sorted[:2]:
                            keyword_lower = keyword.lower()
                            
                            # Exact match
                            if keyword_lower in product_name_lower:
                                matched = True
                                break
                            
                            # Synonym match
                            for main_term, synonyms in synonym_map.items():
                                if keyword_lower in main_term or main_term in keyword_lower:
                                    if any(syn in product_name_lower for syn in synonyms):
                                        matched = True
                                        break
                                if matched:
                                    break
                            
                            if matched:
                                break
                            
                            # Fuzzy match (n·∫øu kh√¥ng c√≥ exact/synonym match)
                            if not matched:
                                try:
                                    from difflib import SequenceMatcher
                                    product_words = product_name_lower.split()
                                    for word in product_words:
                                        if len(word) >= 3 and len(keyword_lower) >= 3:
                                            similarity = SequenceMatcher(None, keyword_lower, word).ratio()
                                            if similarity > 0.7:  # 70% similarity
                                                matched = True
                                                break
                                    if matched:
                                        break
                                except:
                                    pass
                        
                        if matched:
                            products.append({
                                "product_id": str(product_id),
                                "product_name": str(product_name),
                                "category_id": str(cat_id) if cat_id else "",
                                "category_name": str(cat_name) if cat_name else "",
                                "price": float(price) if price is not None else None,
                                "unit": str(don_vi_tinh) if don_vi_tinh else "",
                                "description": str(description) if description else "",
                                "similarity": 1.0,  # SQL exact match => max relevance
                                "source": "sql_exact_match"
                            })
                        else:
                            # Log warning n·∫øu entity kh√¥ng match
                            self.log(f"‚ö†Ô∏è Entity mismatch: '{product_name}' does not match keywords {keywords_sorted[:2]}")
                    
                    cursor.close()
                    return products
                    
                except Exception as e:
                    self.log(f"Error in SQL exact match: {str(e)}", level="error")
                    return []
                finally:
                    if conn:
                        conn.close()
            
            # üî• FIX: Ch·∫°y sync function trong thread pool (pyodbc l√† blocking I/O)
            results = await asyncio.to_thread(search_in_db)
            return results
            
        except Exception as e:
            self.log(f"Error in SQL exact match: {str(e)}", level="error")
            return []
    
    async def _search_by_sql_fuzzy_match(
        self,
        query: str,
        category_id: Optional[str] = None,
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """
        üî• NEW: Fuzzy SQL search - fallback when exact match fails
        Uses partial matching, description search, and relevance scoring
        """
        try:
            connection_string = Settings.DATABASE_CONNECTION_STRING
            if not connection_string:
                self.log("‚ö†Ô∏è DATABASE_CONNECTION_STRING not found. Skipping fuzzy SQL search.")
                return []
            
            import pyodbc
            import asyncio
            
            # Check driver availability
            try:
                test_conn = pyodbc.connect(connection_string, timeout=2)
                test_conn.close()
            except pyodbc.Error as e:
                error_code = str(e)
                if "IM002" in error_code or "driver" in error_code.lower():
                    self.log(f"‚ö†Ô∏è ODBC Driver not available: {error_code}. Skipping fuzzy SQL search.")
                    return []
                raise
            
            # Extract keywords
            keywords = query.split()
            if not keywords:
                return []
            
            keywords_sorted = sorted(keywords, key=len, reverse=True)
            
            def search_in_db():
                """Fuzzy search with relevance scoring"""
                conn = None
                try:
                    conn = pyodbc.connect(connection_string)
                    cursor = conn.cursor()
                    
                    # Build search patterns
                    keyword = keywords_sorted[0]
                    exact_pattern = f"%{keyword}%"
                    
                    # Fuzzy patterns (remove last char for typo tolerance)
                    fuzzy_pattern = f"%{keyword[:-1]}%" if len(keyword) > 2 else exact_pattern
                    
                    # Search in both name and description
                    db_query = f"""
                        SELECT TOP {top_k}
                            s.MaSanPham,
                            s.TenSanPham,
                            s.MoTa,
                            s.Anh,
                            s.GiaBan,
                            s.DonViTinh,
                            s.MaDanhMuc,
                            dm.TenDanhMuc,
                            -- Relevance score
                            CASE 
                                WHEN s.TenSanPham LIKE ? THEN 100
                                WHEN s.TenSanPham LIKE ? THEN 80
                                WHEN s.MoTa LIKE ? THEN 60
                                ELSE 40
                            END AS relevance_score
                        FROM SanPham s
                        LEFT JOIN DanhMuc dm ON s.MaDanhMuc = dm.MaDanhMuc
                        WHERE (s.IsDeleted = 0 OR s.IsDeleted IS NULL)
                          AND (
                              s.TenSanPham LIKE ?
                              OR s.TenSanPham LIKE ?
                              OR s.MoTa LIKE ?
                          )
                        ORDER BY relevance_score DESC, s.TenSanPham
                    """
                    
                    cursor.execute(
                        db_query, 
                        exact_pattern, fuzzy_pattern, exact_pattern,  # For CASE scoring
                        exact_pattern, fuzzy_pattern, exact_pattern   # For WHERE clause
                    )
                    rows = cursor.fetchall()
                    
                    products = []
                    for row in rows:
                        product_id, product_name, description, image_filename, price, don_vi_tinh, cat_id, cat_name, relevance = row
                        
                        # Validate with synonym matching
                        product_name_lower = product_name.lower()
                        
                        synonym_map = {
                            "c√° h·ªìi": ["c√° h·ªìi", "salmon", "c√° h·ªìi na uy", "c√° h·ªìi t∆∞∆°i", "ca hoi"],
                            "th·ªãt b√≤": ["th·ªãt b√≤", "beef", "th·ªãt b√≤ t∆∞∆°i", "thit bo"],
                            "th·ªãt heo": ["th·ªãt heo", "pork", "th·ªãt l·ª£n", "thit heo"],
                            "g√†": ["g√†", "chicken", "g√† ta", "ga"],
                            "t√¥m": ["t√¥m", "shrimp", "t√¥m s√∫", "tom"],
                        }
                        
                        # Check if product matches query intent
                        matched = False
                        for keyword in keywords_sorted[:2]:
                            keyword_lower = keyword.lower()
                            
                            # Exact match
                            if keyword_lower in product_name_lower:
                                matched = True
                                break
                            
                            # Synonym match
                            for main_term, synonyms in synonym_map.items():
                                if keyword_lower in main_term or main_term in keyword_lower:
                                    if any(syn in product_name_lower for syn in synonyms):
                                        matched = True
                                        break
                                if matched:
                                    break
                            
                            if matched:
                                break
                            
                            # Fuzzy match (Levenshtein-like)
                            if not matched and len(keyword_lower) >= 3:
                                try:
                                    from difflib import SequenceMatcher
                                    product_words = product_name_lower.split()
                                    for word in product_words:
                                        if len(word) >= 3:
                                            similarity = SequenceMatcher(None, keyword_lower, word).ratio()
                                            if similarity > 0.7:  # 70% similarity
                                                matched = True
                                                break
                                    if matched:
                                        break
                                except:
                                    pass
                        
                        if matched:
                            products.append({
                                "product_id": str(product_id),
                                "product_name": str(product_name),
                                "category_id": str(cat_id) if cat_id else "",
                                "category_name": str(cat_name) if cat_name else "",
                                "price": float(price) if price is not None else None,
                                "unit": str(don_vi_tinh) if don_vi_tinh else "",
                                "description": str(description) if description else "",
                                "similarity": relevance / 100.0,
                                "source": "sql_fuzzy_match"
                            })
                        else:
                            self.log(f"‚ö†Ô∏è Fuzzy match rejected: '{product_name}' - no keyword match with {keywords_sorted[:2]}")
                    
                    cursor.close()
                    return products
                    
                except Exception as e:
                    self.log(f"Error in fuzzy SQL search: {str(e)}", level="error")
                    return []
                finally:
                    if conn:
                        conn.close()
            
            results = await asyncio.to_thread(search_in_db)
            return results
            
        except Exception as e:
            self.log(f"Error in fuzzy SQL search: {str(e)}", level="error")
            return []

