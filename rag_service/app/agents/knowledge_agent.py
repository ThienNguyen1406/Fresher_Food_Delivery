"""
Knowledge Agent - RAG search tá»« vector store
"""
from typing import Dict, Any, List, Optional
import asyncio
import logging
import hashlib
from app.agents.base_agent import BaseAgent
from app.api.deps import get_image_vector_store, get_image_embedding_service, get_embedding_service
from app.infrastructure.vector_store.image_vector_store import ImageVectorStore
from app.services.image import ImageEmbeddingService
from app.services.embedding import EmbeddingService
from app.core.settings import Settings

logger = logging.getLogger(__name__)


class KnowledgeAgent(BaseAgent):
    """
    Knowledge Agent thá»±c hiá»‡n RAG search:
    """
    
    def __init__(
        self,
        vector_store: Optional[ImageVectorStore] = None,
        image_embedding_service: Optional[ImageEmbeddingService] = None,
        text_embedding_service: Optional[EmbeddingService] = None
    ):
        super().__init__("KnowledgeAgent")
        self.vector_store = vector_store
        self.image_embedding_service = image_embedding_service
        self.text_embedding_service = text_embedding_service
        
        # ğŸ”¥ PERFORMANCE: Simple in-memory cache for search results
        self._search_cache = {} if Settings.ENABLE_AGENT_CACHE else None
        self._cache_max_size = Settings.AGENT_CACHE_SIZE if Settings.ENABLE_AGENT_CACHE else 0
    
    async def process(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        Thá»±c hiá»‡n RAG search dá»±a trÃªn query type
        """
        query_type = state.get("query_type", "text")
        query = state.get("query", "").strip()
        user_description = state.get("user_description", "")
        image_data = state.get("image_data")
        category_id = state.get("category_id")
        top_k = state.get("top_k", 5)
        
        # Lazy load services if not provided
        if not self.vector_store:
            self.vector_store = get_image_vector_store()
        if not self.image_embedding_service:
            self.image_embedding_service = get_image_embedding_service()
        if not self.text_embedding_service:
            self.text_embedding_service = get_embedding_service()
        
        knowledge_results = []
        knowledge_context = ""
        
        try:
            if query_type == "image" or query_type == "hybrid":
                # Image search
                if image_data:
                    self.log("ğŸ” Performing image search...")
                    image_results = await self._search_by_image(
                        image_data=image_data,
                        category_id=category_id,
                        top_k=top_k
                    )
                    knowledge_results.extend(image_results)
            
            if query_type == "text" or query_type == "hybrid":
                # Text search
                search_text = query or user_description
                if search_text:
                    # Normalize query - loáº¡i bá» tá»« khÃ³a khÃ´ng liÃªn quan Ä‘áº¿n product
                    normalized_query = self._normalize_product_query_for_search(search_text)
                    
                    #  PERFORMANCE: Check cache first
                    cache_key = self._get_cache_key(normalized_query, category_id, top_k)
                    if self._search_cache is not None and cache_key in self._search_cache:
                        self.log(f"âš¡ Cache hit for query: '{normalized_query}'")
                        cached_results = self._search_cache[cache_key]
                        knowledge_results.extend(cached_results)
                    else:
                        self.log(f"ğŸ” Performing text search: '{normalized_query}' (original: '{search_text}')...")
                        
                        # Progressive fallback strategy
                        # Priority: SQL exact > SQL fuzzy > Vector search
                        sql_exact_results = await self._search_by_sql_exact_match(normalized_query, category_id, top_k)
                        text_results = []  # Initialize to avoid undefined error
                        
                        if sql_exact_results:
                            self.log(f"âœ… SQL exact match found: {len(sql_exact_results)} products. Using SQL results.")
                            knowledge_results.extend(sql_exact_results)
                        else:
                            # Try fuzzy SQL search
                            self.log(f"âš ï¸ SQL exact match found 0 results. Trying fuzzy SQL search...")
                            sql_fuzzy_results = await self._search_by_sql_fuzzy_match(normalized_query, category_id, top_k)
                            
                            if sql_fuzzy_results:
                                self.log(f"âœ… SQL fuzzy match found: {len(sql_fuzzy_results)} products. Using fuzzy SQL results.")
                                knowledge_results.extend(sql_fuzzy_results)
                            else:
                                # Last resort: vector search
                                self.log(f"âš ï¸ SQL fuzzy match found 0 results. Falling back to vector search...")
                                text_results = await self._search_by_text(
                                    query=normalized_query,
                                    category_id=category_id,
                                    top_k=top_k
                                )
                                knowledge_results.extend(text_results)
                        
                        # ğŸ”¥ PERFORMANCE: Cache results
                        if self._search_cache is not None:
                            if len(self._search_cache) >= self._cache_max_size:
                                # Remove oldest entry (simple FIFO)
                                oldest_key = next(iter(self._search_cache))
                                del self._search_cache[oldest_key]
                            self._search_cache[cache_key] = knowledge_results.copy()

                    
                    #  Fallback retry náº¿u khÃ´ng tÃ¬m Ä‘Æ°á»£c (chá»‰ khi khÃ´ng cÃ³ SQL results)
                    if not sql_exact_results and not text_results and search_text:
                        extracted_product = self._extract_product_name_from_query(search_text)
                        if extracted_product and extracted_product != normalized_query:
                            self.log(f"ğŸ” Retrying search with extracted product name: '{extracted_product}'...")
                            retry_results = await self._search_by_text(
                                query=extracted_product,
                                category_id=category_id,
                                top_k=top_k
                            )
                            knowledge_results.extend(retry_results)
                            if retry_results:
                                self.log(f"âœ… Found {len(retry_results)} results with extracted product name")
            
            # Merge vÃ  deduplicate results
            knowledge_results = self._merge_results(knowledge_results)
            
            # âš¡ FILTER: Chá»‰ giá»¯ láº¡i results cÃ³ similarity >= 0.5 (50%)
            # TrÃ¡nh tráº£ vá» sáº£n pháº©m khÃ´ng liÃªn quan (vÃ­ dá»¥: "cÃ¡ há»“i" â†’ "thá»‹t bÃ²")
            # Threshold 50% Ä‘áº£m báº£o chá»‰ tráº£ vá» sáº£n pháº©m thá»±c sá»± liÃªn quan
            SIMILARITY_THRESHOLD = 0.5
            similarity_filtered = [
                r for r in knowledge_results 
                if r.get("similarity", 0) >= SIMILARITY_THRESHOLD
            ]
            
            if len(similarity_filtered) < len(knowledge_results):
                self.log(f"âš ï¸ Filtered {len(knowledge_results) - len(similarity_filtered)} results with similarity < {SIMILARITY_THRESHOLD:.0%}")
            
            #  Lexical filter chá»‰ Ä‘á»ƒ rerank, khÃ´ng pháº£i gate
            # LÆ°u original vector results Ä‘á»ƒ fallback náº¿u lexical filter loáº¡i háº¿t
            original_vector_results = similarity_filtered.copy()
            filtered_results = similarity_filtered
            
            # Kiá»ƒm tra keyword matching náº¿u cÃ³ query text (dÃ¹ng fuzzy match)
            # Náº¿u user há»i "cÃ¡ há»“i" nhÆ°ng result lÃ  "thá»‹t bÃ²" â†’ loáº¡i bá»
            if query and filtered_results:
                query_lower = query.lower()
                # Extract keywords tá»« query (loáº¡i bá» stopwords)
                import re
                from difflib import SequenceMatcher
                
                stopwords = {"hÃ¬nh", "áº£nh", "hÃ¬nh áº£nh", "láº¥y", "ra", "vÃ ", "cá»§a", "nÃ³", "theo", "thÃ¡ng", "doanh", "thu", "sá»‘"}
                query_keywords = [w for w in re.sub(r'[^a-zÃ -á»¹\s]', ' ', query_lower).split() 
                                 if w and w not in stopwords and len(w) > 2]
                
                if query_keywords:
                    # Whole-word matching + synonym + fuzzy match
                    truly_matched = []
                    for result in filtered_results:
                        product_name = result.get("product_name", "").lower()
                        
                        # Synonym map
                        synonym_map = {
                            "cÃ¡ há»“i": ["cÃ¡ há»“i", "salmon", "cÃ¡ há»“i na uy", "cÃ¡ há»“i tÆ°Æ¡i"],
                            "thá»‹t bÃ²": ["thá»‹t bÃ²", "beef", "thá»‹t bÃ² tÆ°Æ¡i"],
                            "thá»‹t heo": ["thá»‹t heo", "pork", "thá»‹t lá»£n"],
                            "gÃ ": ["gÃ ", "chicken", "gÃ  ta"],
                            "tÃ´m": ["tÃ´m", "shrimp", "tÃ´m sÃº"],
                        }
                        
                        # Kiá»ƒm tra match vá»›i tá»«ng keyword
                        matched = False
                        for keyword in query_keywords:
                            keyword_lower = keyword.lower()
                            
                            # 1. Whole-word exact match (quan trá»ng nháº¥t)
                            import re
                            # Match whole word, khÃ´ng match substring
                            word_pattern = r'\b' + re.escape(keyword_lower) + r'\b'
                            if re.search(word_pattern, product_name):
                                matched = True
                                break
                            
                            # 2. Synonym match
                            for main_term, synonyms in synonym_map.items():
                                if keyword_lower in main_term or main_term in keyword_lower:
                                    # Check náº¿u product_name chá»©a báº¥t ká»³ synonym nÃ o
                                    if any(re.search(r'\b' + re.escape(syn) + r'\b', product_name) for syn in synonyms):
                                        matched = True
                                        break
                                if matched:
                                    break
                            
                            if matched:
                                break
                            
                            # 3. Fuzzy match (cho phÃ©p typo nhá») - chá»‰ khi khÃ´ng cÃ³ exact/synonym match
                            if not matched and len(keyword_lower) >= 3:
                                product_words = product_name.split()
                                for word in product_words:
                                    if len(word) >= 3:
                                        similarity_ratio = SequenceMatcher(None, keyword_lower, word).ratio()
                                        if similarity_ratio > 0.7:  # 70% similarity
                                            matched = True
                                            break
                                if matched:
                                    break
                        
                        if matched:
                            truly_matched.append(result)
                        else:
                            self.log(f"âš ï¸ Filtered out product '{result.get('product_name')}' - khÃ´ng khá»›p keywords: {query_keywords}")
                    
                    if truly_matched:
                        filtered_results = truly_matched
                    else:
                        #  Náº¿u lexical filter loáº¡i háº¿t â†’ KHÃ”NG fallback vá» vector results
                        # LÃ½ do: Náº¿u vector search tráº£ vá» sai entity (vÃ­ dá»¥: "Thá»‹t bÃ²" khi há»i "cÃ¡ há»“i")
                        # thÃ¬ khÃ´ng nÃªn fallback vá» Ä‘Ã³, mÃ  nÃªn return empty Ä‘á»ƒ hard guard xá»­ lÃ½
                        self.log(f"âš ï¸ Lexical filter removed all results. NOT falling back to vector results to avoid wrong entity.")
                        self.log(f"âš ï¸ This will trigger hard guard in Orchestrator to ask user for clarification.")
                        filtered_results = []  # Return empty Ä‘á»ƒ hard guard xá»­ lÃ½
            
            knowledge_results = filtered_results
            
            # Format context
            knowledge_context = self._format_context(knowledge_results)
            
            self.log(f"âœ… Found {len(knowledge_results)} knowledge results (after filtering)")
            
        except Exception as e:
            self.log(f"âŒ Error in knowledge search: {str(e)}", level="error")
            knowledge_results = []
            knowledge_context = ""
        
        # Cáº­p nháº­t state
        state.update({
            "knowledge_results": knowledge_results,
            "knowledge_context": knowledge_context
        })
        
        return state
    
    async def _search_by_image(
        self,
        image_data: bytes,
        category_id: Optional[str] = None,
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """Search products by image"""
        try:
            # Táº¡o image embedding
            query_embedding = await self.image_embedding_service.create_embedding(image_data)
            
            if query_embedding is None:
                return []
            
            # Build where clause
            where_clause = {"content_type": "product"}
            if category_id:
                where_clause["category_id"] = category_id
            
            # Vector search
            results = await asyncio.to_thread(
                self.vector_store.collection.query,
                query_embeddings=[query_embedding.tolist()],
                n_results=top_k,
                where=where_clause
            )
            
            # Parse results
            products = []
            if results.get('ids') and len(results['ids'][0]) > 0:
                for i in range(len(results['ids'][0])):
                    metadata = results['metadatas'][0][i]
                    distance = results['distances'][0][i] if 'distances' in results and results['distances'] else 1.0
                    similarity = 1 - distance
                    
                    product = {
                        "product_id": metadata.get('file_id', '') or metadata.get('product_id', ''),
                        "product_name": metadata.get('product_name', ''),
                        "category_id": metadata.get('category_id', ''),
                        "category_name": metadata.get('category_name', ''),
                        "similarity": float(similarity),
                        "price": float(metadata.get('price', 0)) if metadata.get('price') else None,
                        "source": "image_search"
                    }
                    products.append(product)
            
            return products
            
        except Exception as e:
            self.log(f"Error in image search: {str(e)}", level="error")
            return []
    
    async def _search_by_text(
        self,
        query: str,
        category_id: Optional[str] = None,
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """Search products by text"""
        try:
            # Táº¡o text embedding (dÃ¹ng CLIP text encoder Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch vá»›i image embeddings)
            query_embedding = self.image_embedding_service.create_text_embedding(query)
            
            if query_embedding is None:
                return []
            
            # Build where clause
            where_clause = {"content_type": "product"}
            if category_id:
                where_clause["category_id"] = category_id
            
            # Vector search
            results = await asyncio.to_thread(
                self.vector_store.collection.query,
                query_embeddings=[query_embedding.tolist()],
                n_results=top_k,
                where=where_clause
            )
            
            # Parse results
            products = []
            if results.get('ids') and len(results['ids'][0]) > 0:
                for i in range(len(results['ids'][0])):
                    metadata = results['metadatas'][0][i]
                    distance = results['distances'][0][i] if 'distances' in results and results['distances'] else 1.0
                    similarity = 1 - distance
                    
                    product = {
                        "product_id": metadata.get('file_id', '') or metadata.get('product_id', ''),
                        "product_name": metadata.get('product_name', ''),
                        "category_id": metadata.get('category_id', ''),
                        "category_name": metadata.get('category_name', ''),
                        "similarity": float(similarity),
                        "price": float(metadata.get('price', 0)) if metadata.get('price') else None,
                        "source": "text_search"
                    }
                    products.append(product)
            
            return products
            
        except Exception as e:
            self.log(f"Error in text search: {str(e)}", level="error")
            return []
    
    def _merge_results(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Merge vÃ  deduplicate results tá»« nhiá»u sources"""
        seen = {}
        merged = []
        
        for result in results:
            product_id = result.get("product_id")
            if not product_id:
                continue
            
            # Náº¿u Ä‘Ã£ cÃ³, chá»n result cÃ³ similarity cao hÆ¡n
            if product_id in seen:
                existing = seen[product_id]
                if result.get("similarity", 0) > existing.get("similarity", 0):
                    seen[product_id] = result
            else:
                seen[product_id] = result
        
        # Sort by similarity
        merged = sorted(seen.values(), key=lambda x: x.get("similarity", 0), reverse=True)
        
        return merged
    
    def _normalize_product_query_for_search(self, query: str) -> str:
        """
        Normalize query cho product search - loáº¡i bá» tá»« khÃ³a khÃ´ng liÃªn quan
        VÃ­ dá»¥: "hÃ¬nh áº£nh cÃ¡ há»“i vÃ  doanh thu theo thÃ¡ng" â†’ "cÃ¡ há»“i"
        Má»¥c tiÃªu: Chá»‰ giá»¯ láº¡i tÃªn sáº£n pháº©m Ä‘á»ƒ vector embedding match tá»‘t hÆ¡n
        """
        import re
        
        if not query:
            return query
        
        q = query.lower()
        
        # Loáº¡i bá» tá»« khÃ³a nhiá»…u (noise words) - Æ°u tiÃªn loáº¡i bá» cá»¥m tá»« trÆ°á»›c
        noise_phrases = [
            "hÃ¬nh áº£nh", "áº£nh", "image", "picture",
            "doanh thu", "doanh sá»‘", "thá»‘ng kÃª", "theo thÃ¡ng", 
            "bÃ¡n cháº¡y", "giÃ¡ bao nhiÃªu", "revenue", "sales",
            "láº¥y ra", "láº¥y", "hiá»ƒn thá»‹", "show", "display"
        ]
        
        # Loáº¡i bá» cá»¥m tá»« trÆ°á»›c (Ä‘á»ƒ trÃ¡nh "hÃ¬nh áº£nh" â†’ "hÃ¬nh" + "áº£nh" cÃ²n sÃ³t)
        for phrase in noise_phrases:
            q = q.replace(phrase, " ")
        
        # Loáº¡i bá» tá»« Ä‘Æ¡n láº»
        noise_words = [
            "vÃ ", "cá»§a", "nÃ³", "cho", "tá»«", "Ä‘áº¿n", "trong", "ngoÃ i",
            "ra", "vá»", "vá»›i", "nÄƒm", "thÃ¡ng", "ngÃ y"
        ]
        
        for word in noise_words:
            # Chá»‰ replace náº¿u lÃ  tá»« Ä‘Æ¡n láº» (cÃ³ space xung quanh hoáº·c Ä‘áº§u/cuá»‘i)
            q = re.sub(rf'\b{re.escape(word)}\b', ' ', q)
        
        # Clean up multiple spaces
        q = re.sub(r'\s+', ' ', q).strip()
        
        # Náº¿u normalized quÃ¡ ngáº¯n hoáº·c rá»—ng, dÃ¹ng query gá»‘c
        if len(q) < 2:
            q = query.strip()
        
        self.log(f"ğŸ” Normalized query: '{q}' (from '{query}')")
        return q
    
    def _extract_product_name_from_query(self, query: str) -> Optional[str]:
        """
        Extract product name tá»« query phá»©c táº¡p.
        VÃ­ dá»¥: "hÃ¬nh áº£nh cÃ¡ há»“i vÃ  doanh thu theo thÃ¡ng" â†’ "cÃ¡ há»“i"
        """
        import re
        
        # Loáº¡i bá» cÃ¡c tá»« khÃ´ng quan trá»ng (stopwords)
        stopwords = {
            "hÃ¬nh", "áº£nh", "hÃ¬nh áº£nh", "hinh", "anh",
            "láº¥y", "lay", "ra", "xem", "xem thá»­",
            "sáº£n", "pháº©m", "san", "pham", "sáº£n pháº©m",
            "cá»§a", "vá»", "vá»›i", "giÃºp", "mÃ¬nh", "tÃ´i",
            "vÃ ", "cÅ©ng", "nhÆ°", "lÃ ", "cÃ³", "khÃ´ng",
            "theo", "thÃ¡ng", "doanh", "thu", "sá»‘", "thá»‘ng", "kÃª",
            "nÃ³", "cho", "tá»«", "Ä‘áº¿n", "trong", "ngoÃ i", "nÄƒm"
        }
        
        # Normalize query
        query_lower = query.lower()
        query_clean = re.sub(r'[^\w\s]', ' ', query_lower)
        words = [w for w in query_clean.split() if w and w not in stopwords and len(w) > 2]
        
        # ğŸ”¥ Cáº¢I THIá»†N: TÃ¬m cá»¥m tá»« phá»• biáº¿n cho tÃªn sáº£n pháº©m thá»±c pháº©m
        # VÃ­ dá»¥: "cÃ¡ há»“i", "thá»‹t bÃ²", "rau cáº£i", "gÃ  nÆ°á»›ng"
        common_product_patterns = [
            r"cÃ¡\s+\w+",  # "cÃ¡ há»“i", "cÃ¡ thu"
            r"thá»‹t\s+\w+",  # "thá»‹t bÃ²", "thá»‹t heo"
            r"rau\s+\w+",  # "rau cáº£i", "rau muá»‘ng"
            r"gÃ \s+\w+",  # "gÃ  nÆ°á»›ng", "gÃ  rÃ¡n"
            r"tÃ´m\s+\w+",  # "tÃ´m sÃº", "tÃ´m hÃ¹m"
            r"khoai\s+\w+",  
            r"nÆ°á»›c\s+\w+",  
            r"sá»¯a\s+\w+",
        ]
        
        for pattern in common_product_patterns:
            match = re.search(pattern, query_lower)
            if match:
                extracted = match.group(0).strip()
                if len(extracted) >= 4:  # Äáº£m báº£o Ä‘á»§ dÃ i
                    self.log(f"âœ… Extracted product name using pattern: '{extracted}'")
                    return extracted
        
        # Náº¿u khÃ´ng match pattern, thá»­ cá»¥m 2 tá»« liÃªn tiáº¿p
        if len(words) >= 2:
            # Thá»­ cá»¥m 2 tá»« trÆ°á»›c (thÆ°á»ng lÃ  tÃªn sáº£n pháº©m)
            for i in range(len(words) - 1):
                phrase = f"{words[i]} {words[i+1]}"
                if len(phrase) >= 4:  # Äáº£m báº£o Ä‘á»§ dÃ i
                    self.log(f"âœ… Extracted product name: '{phrase}'")
                    return phrase
        elif len(words) == 1:
            self.log(f"âœ… Extracted product name (single word): '{words[0]}'")
            return words[0]
        
        # Náº¿u khÃ´ng extract Ä‘Æ°á»£c, tráº£ vá» None
        self.log(f"âš ï¸ Could not extract product name from query: '{query[:50]}'")
        return None
    
    def _format_context(self, results: List[Dict[str, Any]]) -> str:
        """Format search results thÃ nh context string"""
        if not results:
            return ""
        
        context_parts = []
        for i, result in enumerate(results[:5], 1):  # Top 5 results
            product_name = result.get("product_name", "Unknown")
            category_name = result.get("category_name", "")
            price = result.get("price")
            similarity = result.get("similarity", 0)
            
            context = f"{i}. {product_name}"
            if category_name:
                context += f" (Danh má»¥c: {category_name})"
            if price:
                context += f" - GiÃ¡: {price:,.0f} VND"
            context += f" (Äá»™ tÆ°Æ¡ng Ä‘á»“ng: {similarity:.2%})"
            
            context_parts.append(context)
        
        return "\n".join(context_parts)
    
    def _build_odbc_connection_with_fallback(self, connection_string: str) -> Optional[Any]:
        """
        Build ODBC connection vá»›i fallback driver logic (giá»‘ng /api/products/search/chat)
        Thá»­ nhiá»u driver khÃ¡c nhau Ä‘á»ƒ tÃ¬m driver phÃ¹ há»£p
        """
        import pyodbc
        import re
        
        if not connection_string:
            return None
        
        # Build ODBC connection string náº¿u chÆ°a cÃ³ DRIVER
        conn_str = connection_string
        if "DRIVER=" not in conn_str.upper():
            params = {}
            parts = [p.strip() for p in conn_str.split(';') if p.strip()]
            for part in parts:
                if '=' in part:
                    key, value = part.split('=', 1)
                    params[key.strip().lower()] = value.strip()

            server = params.get('server', '')
            database = params.get('database', '')
            user_id = params.get('user id', params.get('uid', ''))
            password = params.get('password', params.get('pwd', ''))
            trust_cert = params.get('trustservercertificate', 'True').lower() == 'true'

            driver = "ODBC Driver 18 for SQL Server"
            odbc_conn_str = f"DRIVER={{{driver}}};SERVER={server};DATABASE={database};"
            if user_id:
                odbc_conn_str += f"UID={user_id};PWD={password};"
            if trust_cert:
                odbc_conn_str += "TrustServerCertificate=yes;"
            conn_str = odbc_conn_str

        # ğŸ”¥ FALLBACK: Thá»­ nhiá»u driver khÃ¡c nhau
        conn = None
        for driver_name in ["ODBC Driver 18 for SQL Server", "ODBC Driver 17 for SQL Server", "SQL Server Native Client 11.0"]:
            try:
                test_conn_str = conn_str
                if driver_name not in test_conn_str:
                    test_conn_str = re.sub(r'DRIVER=\{[^}]+\}', f'DRIVER={{{driver_name}}}', test_conn_str, count=1)
                conn = pyodbc.connect(test_conn_str, timeout=5)
                self.log(f"âœ… Connected to DB using driver: {driver_name}")
                break
            except Exception as e:
                continue
        
        return conn
    
    async def _search_by_sql_exact_match(
        self,
        query: str,
        category_id: Optional[str] = None,
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """
        SQL exact match TRÆ¯á»šC vector search
        TÃ¬m sáº£n pháº©m báº±ng SQL LIKE Ä‘á»ƒ Ä‘áº£m báº£o entity match chÃ­nh xÃ¡c
        """
        try:
            connection_string = Settings.DATABASE_CONNECTION_STRING
            if not connection_string:
                self.log("âš ï¸ DATABASE_CONNECTION_STRING not found. Skipping SQL exact match.")
                return []
            
            import asyncio
            
            # Sá»­ dá»¥ng fallback driver logic
            # Test connection vá»›i fallback driver
            test_conn = self._build_odbc_connection_with_fallback(connection_string)
            if not test_conn:
                self.log("âš ï¸ Could not establish DB connection with any driver. Skipping SQL exact match.")
                return []
            test_conn.close()
            
            # Extract keywords tá»« query Ä‘á»ƒ search
            keywords = query.split()
            if not keywords:
                return []
            
            # Thá»­ search vá»›i tá»«ng keyword, Æ°u tiÃªn keyword dÃ i nháº¥t
            keywords_sorted = sorted(keywords, key=len, reverse=True)
            
            # ğŸ”¥ FIX: Chuyá»ƒn thÃ nh sync function Ä‘á»ƒ dÃ¹ng vá»›i asyncio.to_thread
            def search_in_db():
                """Sync function Ä‘á»ƒ cháº¡y trong thread pool"""
                conn = None
                try:
                    # Sá»­ dá»¥ng fallback driver logic
                    conn = self._build_odbc_connection_with_fallback(connection_string)
                    if not conn:
                        return []
                    cursor = conn.cursor()
                    
                    # Search vá»›i keyword Ä‘áº§u tiÃªn (dÃ i nháº¥t)
                    keyword = keywords_sorted[0]
                    like_pattern = f"%{keyword}%"
                    
                    # ğŸ”¥ FIX: ThÃªm filter category_id náº¿u cÃ³
                    category_filter = ""
                    query_params = [like_pattern]
                    if category_id:
                        category_filter = " AND s.MaDanhMuc = ?"
                        query_params.append(category_id)
                    
                    db_query = f"""
                        SELECT TOP {top_k}
                            s.MaSanPham,
                            s.TenSanPham,
                            s.MoTa,
                            s.Anh,
                            s.GiaBan,
                            s.DonViTinh,
                            s.MaDanhMuc,
                            dm.TenDanhMuc
                        FROM SanPham s
                        LEFT JOIN DanhMuc dm ON s.MaDanhMuc = dm.MaDanhMuc
                        WHERE (s.IsDeleted = 0 OR s.IsDeleted IS NULL)
                          AND s.TenSanPham LIKE ?{category_filter}
                        ORDER BY
                            CASE WHEN s.TenSanPham LIKE ? THEN 0 ELSE 1 END,
                            s.TenSanPham
                    """
                    
                    query_params.append(like_pattern)  # For ORDER BY CASE
                    cursor.execute(db_query, *query_params)
                    rows = cursor.fetchall()
                    
                    products = []
                    for row in rows:
                        product_id, product_name, description, image_filename, price, don_vi_tinh, cat_id, cat_name = row
                        
                        # ğŸ”¥ BONUS: Guardrail chá»‘ng nháº§m sáº£n pháº©m vá»›i synonym + fuzzy match
                        product_name_lower = product_name.lower()
                        
                        # Synonym map cho cÃ¡c sáº£n pháº©m phá»• biáº¿n
                        synonym_map = {
                            "cÃ¡ há»“i": ["cÃ¡ há»“i", "salmon", "cÃ¡ há»“i na uy", "cÃ¡ há»“i tÆ°Æ¡i"],
                            "thá»‹t bÃ²": ["thá»‹t bÃ²", "beef", "thá»‹t bÃ² tÆ°Æ¡i"],
                            "thá»‹t heo": ["thá»‹t heo", "pork", "thá»‹t lá»£n"],
                            "gÃ ": ["gÃ ", "chicken", "gÃ  ta", "gÃ  cÃ´ng nghiá»‡p"],
                            "tÃ´m": ["tÃ´m", "shrimp", "tÃ´m sÃº", "tÃ´m hÃ¹m"],
                        }
                        
                        # Kiá»ƒm tra match vá»›i synonym
                        matched = False
                        for keyword in keywords_sorted[:2]:
                            keyword_lower = keyword.lower()
                            
                            # Exact match
                            if keyword_lower in product_name_lower:
                                matched = True
                                break
                            
                            # Synonym match
                            for main_term, synonyms in synonym_map.items():
                                if keyword_lower in main_term or main_term in keyword_lower:
                                    if any(syn in product_name_lower for syn in synonyms):
                                        matched = True
                                        break
                                if matched:
                                    break
                            
                            if matched:
                                break
                            
                            # Fuzzy match (náº¿u khÃ´ng cÃ³ exact/synonym match)
                            if not matched:
                                try:
                                    from difflib import SequenceMatcher
                                    product_words = product_name_lower.split()
                                    for word in product_words:
                                        if len(word) >= 3 and len(keyword_lower) >= 3:
                                            similarity = SequenceMatcher(None, keyword_lower, word).ratio()
                                            if similarity > 0.7:  # 70% similarity
                                                matched = True
                                                break
                                    if matched:
                                        break
                                except:
                                    pass
                        
                        if matched:
                            products.append({
                                "product_id": str(product_id),
                                "product_name": str(product_name),
                                "category_id": str(cat_id) if cat_id else "",
                                "category_name": str(cat_name) if cat_name else "",
                                "price": float(price) if price is not None else None,
                                "unit": str(don_vi_tinh) if don_vi_tinh else "",
                                "description": str(description) if description else "",
                                "similarity": 1.0,  # SQL exact match => max relevance
                                "source": "sql_exact_match"
                            })
                        else:
                            # Log warning náº¿u entity khÃ´ng match
                            self.log(f"âš ï¸ Entity mismatch: '{product_name}' does not match keywords {keywords_sorted[:2]}")
                    
                    cursor.close()
                    return products
                    
                except Exception as e:
                    self.log(f"Error in SQL exact match: {str(e)}", level="error")
                    return []
                finally:
                    if conn:
                        conn.close()
            
            # ğŸ”¥ FIX: Cháº¡y sync function trong thread pool (pyodbc lÃ  blocking I/O)
            results = await asyncio.to_thread(search_in_db)
            return results
            
        except Exception as e:
            self.log(f"Error in SQL exact match: {str(e)}", level="error")
            return []
    
    async def _search_by_sql_fuzzy_match(
        self,
        query: str,
        category_id: Optional[str] = None,
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """
        ğŸ”¥ NEW: Fuzzy SQL search - fallback when exact match fails
        Uses partial matching, description search, and relevance scoring
        """
        try:
            connection_string = Settings.DATABASE_CONNECTION_STRING
            if not connection_string:
                self.log("âš ï¸ DATABASE_CONNECTION_STRING not found. Skipping fuzzy SQL search.")
                return []
            
            import asyncio
            
            # ğŸ”¥ FIX: Sá»­ dá»¥ng fallback driver logic
            test_conn = self._build_odbc_connection_with_fallback(connection_string)
            if not test_conn:
                self.log("âš ï¸ Could not establish DB connection with any driver. Skipping fuzzy SQL search.")
                return []
            test_conn.close()
            
            # Extract keywords
            keywords = query.split()
            if not keywords:
                return []
            
            keywords_sorted = sorted(keywords, key=len, reverse=True)
            
            def search_in_db():
                """Fuzzy search with relevance scoring"""
                conn = None
                try:
                    # Sá»­ dá»¥ng fallback driver logic
                    conn = self._build_odbc_connection_with_fallback(connection_string)
                    if not conn:
                        return []
                    cursor = conn.cursor()
                    
                    # Build search patterns
                    keyword = keywords_sorted[0]
                    exact_pattern = f"%{keyword}%"
                    
                    # Fuzzy patterns (remove last char for typo tolerance)
                    fuzzy_pattern = f"%{keyword[:-1]}%" if len(keyword) > 2 else exact_pattern
                    
                    # ğŸ”¥ FIX: ThÃªm filter category_id náº¿u cÃ³
                    category_filter = ""
                    query_params = []
                    if category_id:
                        category_filter = " AND s.MaDanhMuc = ?"
                        query_params.append(category_id)
                    
                    # Search in both name and description
                    db_query = f"""
                        SELECT TOP {top_k}
                            s.MaSanPham,
                            s.TenSanPham,
                            s.MoTa,
                            s.Anh,
                            s.GiaBan,
                            s.DonViTinh,
                            s.MaDanhMuc,
                            dm.TenDanhMuc,
                            -- Relevance score
                            CASE 
                                WHEN s.TenSanPham LIKE ? THEN 100
                                WHEN s.TenSanPham LIKE ? THEN 80
                                WHEN s.MoTa LIKE ? THEN 60
                                ELSE 40
                            END AS relevance_score
                        FROM SanPham s
                        LEFT JOIN DanhMuc dm ON s.MaDanhMuc = dm.MaDanhMuc
                        WHERE (s.IsDeleted = 0 OR s.IsDeleted IS NULL)
                          AND (
                              s.TenSanPham LIKE ?
                              OR s.TenSanPham LIKE ?
                              OR s.MoTa LIKE ?
                          ){category_filter}
                        ORDER BY relevance_score DESC, s.TenSanPham
                    """
                    
                    # Build query parameters: CASE scoring + WHERE clause + category filter
                    all_params = [
                        exact_pattern, fuzzy_pattern, exact_pattern,  # For CASE scoring
                        exact_pattern, fuzzy_pattern, exact_pattern   # For WHERE clause
                    ]
                    if category_id:
                        all_params.insert(-3, category_id)  # Insert before WHERE clause params
                    
                    cursor.execute(db_query, *all_params)
                    rows = cursor.fetchall()
                    
                    products = []
                    for row in rows:
                        product_id, product_name, description, image_filename, price, don_vi_tinh, cat_id, cat_name, relevance = row
                        
                        # Validate with synonym matching
                        product_name_lower = product_name.lower()
                        
                        synonym_map = {
                            "cÃ¡ há»“i": ["cÃ¡ há»“i", "salmon", "cÃ¡ há»“i na uy", "cÃ¡ há»“i tÆ°Æ¡i", "ca hoi"],
                            "thá»‹t bÃ²": ["thá»‹t bÃ²", "beef", "thá»‹t bÃ² tÆ°Æ¡i", "thit bo"],
                            "thá»‹t heo": ["thá»‹t heo", "pork", "thá»‹t lá»£n", "thit heo"],
                            "gÃ ": ["gÃ ", "chicken", "gÃ  ta", "ga"],
                            "tÃ´m": ["tÃ´m", "shrimp", "tÃ´m sÃº", "tom"],
                        }
                        
                        # Check if product matches query intent
                        matched = False
                        for keyword in keywords_sorted[:2]:
                            keyword_lower = keyword.lower()
                            
                            # Exact match
                            if keyword_lower in product_name_lower:
                                matched = True
                                break
                            
                            # Synonym match
                            for main_term, synonyms in synonym_map.items():
                                if keyword_lower in main_term or main_term in keyword_lower:
                                    if any(syn in product_name_lower for syn in synonyms):
                                        matched = True
                                        break
                                if matched:
                                    break
                            
                            if matched:
                                break
                            
                            # Fuzzy match (Levenshtein-like)
                            if not matched and len(keyword_lower) >= 3:
                                try:
                                    from difflib import SequenceMatcher
                                    product_words = product_name_lower.split()
                                    for word in product_words:
                                        if len(word) >= 3:
                                            similarity = SequenceMatcher(None, keyword_lower, word).ratio()
                                            if similarity > 0.7:  # 70% similarity
                                                matched = True
                                                break
                                    if matched:
                                        break
                                except:
                                    pass
                        
                        if matched:
                            products.append({
                                "product_id": str(product_id),
                                "product_name": str(product_name),
                                "category_id": str(cat_id) if cat_id else "",
                                "category_name": str(cat_name) if cat_name else "",
                                "price": float(price) if price is not None else None,
                                "unit": str(don_vi_tinh) if don_vi_tinh else "",
                                "description": str(description) if description else "",
                                "similarity": relevance / 100.0,
                                "source": "sql_fuzzy_match"
                            })
                        else:
                            self.log(f"âš ï¸ Fuzzy match rejected: '{product_name}' - no keyword match with {keywords_sorted[:2]}")
                    
                    cursor.close()
                    return products
                    
                except Exception as e:
                    self.log(f"Error in fuzzy SQL search: {str(e)}", level="error")
                    return []
                finally:
                    if conn:
                        conn.close()
            
            results = await asyncio.to_thread(search_in_db)
            return results
            
        except Exception as e:
            self.log(f"Error in fuzzy SQL search: {str(e)}", level="error")
            return []
    
    def _get_cache_key(self, query: str, category_id: Optional[str], top_k: int) -> str:
        """Generate cache key for search results"""
        key_str = f"{query.lower().strip()}:{category_id or 'all'}:{top_k}"
        return hashlib.md5(key_str.encode()).hexdigest()
