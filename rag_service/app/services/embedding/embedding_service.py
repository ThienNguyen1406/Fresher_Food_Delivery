import os
import logging
from typing import List, Optional
import numpy as np
import asyncio

from app.core.settings import Settings

logger = logging.getLogger(__name__)


class EmbeddingService:
    """
    Service t·∫°o embedding vectors t·ª´ text
    """
    
    def __init__(self):
        """Kh·ªüi t·∫°o Embedding Service"""
        self.embedding_model = None
        self.use_openai = Settings.USE_OPENAI_EMBEDDINGS
        self.openai_api_key = Settings.OPENAI_API_KEY
        
        # Khuy·∫øn ngh·ªã: S·ª≠ d·ª•ng OpenAI embeddings (text-embedding-3-large)
        if self.use_openai and self.openai_api_key:
            logger.info("‚úÖ ƒêang s·ª≠ d·ª•ng OpenAI embeddings (khuy·∫øn ngh·ªã: text-embedding-3-large)")
            self._init_openai()
        else:
            if self.use_openai:
                logger.warning("‚ö†Ô∏è  OpenAI embeddings ƒë∆∞·ª£c b·∫≠t nh∆∞ng ch∆∞a c√≥ API Key!")
                logger.warning("   ƒê·ªÉ c·∫•u h√¨nh: Th√™m OPENAI_API_KEY v√†o file .env ho·∫∑c environment variable")
                logger.warning("   Xem SETUP.md ƒë·ªÉ bi·∫øt chi ti·∫øt")
            logger.info("üîÑ Chuy·ªÉn sang Sentence Transformer (ch·∫≠m h∆°n nh∆∞ng mi·ªÖn ph√≠)")
            self._init_sentence_transformer()
    
    def _init_openai(self):
        """Kh·ªüi t·∫°o OpenAI embeddings - Khuy·∫øn ngh·ªã: text-embedding-3-large"""
        try:
            import openai
            from openai import OpenAI
            
            # T·∫°o client v·ªõi timeout
            self.openai_client = OpenAI(
                api_key=self.openai_api_key,
                timeout=60.0,  # Timeout 60 gi√¢y cho m·ªói request
                max_retries=2  # Retry t·ªëi ƒëa 2 l·∫ßn
            )
            # S·ª≠ d·ª•ng model t·ª´ settings (m·∫∑c ƒë·ªãnh: text-embedding-3-large)
            self.embedding_model = Settings.EMBEDDING_MODEL
            logger.info(f"OpenAI embedding model: {self.embedding_model}")
        except ImportError:
            logger.warning("OpenAI library ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t, chuy·ªÉn sang Sentence Transformer")
            self.use_openai = False
            self._init_sentence_transformer()
    
    def _init_sentence_transformer(self):
        """Kh·ªüi t·∫°o Sentence Transformer (fallback khi kh√¥ng c√≥ OpenAI)"""
        try:
            from sentence_transformers import SentenceTransformer
            model_name = Settings.EMBEDDING_MODEL
            self.embedding_model = SentenceTransformer(model_name)
            logger.info(f"ƒê√£ t·∫£i Sentence Transformer model: {model_name}")
        except ImportError:
            logger.error("Sentence Transformer ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. Vui l√≤ng c√†i: pip install sentence-transformers")
            raise
        except Exception as e:
            logger.error(f"L·ªói khi t·∫£i Sentence Transformer: {str(e)}")
            raise
    
    async def create_embedding(self, text: str) -> Optional[np.ndarray]:
        """Create embedding vector from text"""
        if not text or not text.strip():
            return None
        
        try:
            if self.use_openai:
                return await self._create_openai_embedding(text)
            else:
                return self._create_sentence_transformer_embedding(text)
        except Exception as e:
            logger.error(f"Error creating embedding: {str(e)}")
            return None
    
    async def _create_openai_embedding(self, text: str) -> np.ndarray:
        """
        T·∫°o embedding s·ª≠ d·ª•ng OpenAI API (single text)
        T·ªêI ∆ØU: S·ª≠ d·ª•ng async client tr·ª±c ti·∫øp thay v√¨ to_thread ƒë·ªÉ nhanh h∆°n
        """
        try:
            import asyncio
            response = await asyncio.to_thread(
                self.openai_client.embeddings.create,
                model=self.embedding_model,
                input=text,
                timeout=5.0  # T·ªêI ∆ØU: Gi·∫£m timeout t·ª´ 10s xu·ªëng 5s
            )
            embedding = response.data[0].embedding
            return np.array(embedding, dtype=np.float32)
        except Exception as e:
            logger.error(f"L·ªói khi t·∫°o OpenAI embedding: {str(e)}")
            raise
    
    def _create_sentence_transformer_embedding(self, text: str) -> np.ndarray:
        """Create embedding using Sentence Transformer"""
        embedding = self.embedding_model.encode(text, convert_to_numpy=True)
        return embedding.astype(np.float32)
    
    async def create_embeddings(self, texts: List[str]) -> List[Optional[np.ndarray]]:
        """
        T·∫°o embeddings cho nhi·ªÅu texts
        """
        if not texts:
            return []
        
        try:
            if self.use_openai:
                # OpenAI h·ªó tr·ª£ batch, t·∫°o embeddings cho nhi·ªÅu texts c√πng l√∫c
                # Gi·ªõi h·∫°n batch size ƒë·ªÉ tr√°nh qu√° t·∫£i
                batch_size = 100  # OpenAI cho ph√©p t·ªëi ƒëa 2048 texts
                embeddings = []
                
                logger.info(f"ƒêang t·∫°o embeddings cho {len(texts)} chunks (batch size: {batch_size})")
                
                # X·ª≠ l√Ω theo batch
                for i in range(0, len(texts), batch_size):
                    batch = texts[i:i + batch_size]
                    logger.info(f"Processing batch {i//batch_size + 1}/{(len(texts) + batch_size - 1)//batch_size} ({len(batch)} texts)")
                    
                    try:
                        # G·ªçi OpenAI API v·ªõi batch (s·ª≠ d·ª•ng asyncio.to_thread)
                        import asyncio
                        response = await asyncio.to_thread(
                            self.openai_client.embeddings.create,
                            model=self.embedding_model,
                            input=batch,
                            timeout=30.0  # Timeout 30 gi√¢y cho batch
                        )
                        
                        # L·∫•y embeddings t·ª´ response
                        batch_embeddings = [
                            np.array(item.embedding, dtype=np.float32) 
                            for item in response.data
                        ]
                        embeddings.extend(batch_embeddings)
                        
                        logger.info(f"‚úÖ ƒê√£ t·∫°o embeddings cho batch {i//batch_size + 1} ({len(batch_embeddings)} embeddings)")
                        
                    except Exception as e:
                        logger.error(f"‚ùå L·ªói khi t·∫°o embeddings cho batch {i//batch_size + 1}: {str(e)}", exc_info=True)
                        # Th√™m None cho batch n√†y ƒë·ªÉ kh√¥ng l√†m gi√°n ƒëo·∫°n qu√° tr√¨nh
                        embeddings.extend([None] * len(batch))
                
                logger.info(f"Ho√†n th√†nh t·∫°o embeddings: {len([e for e in embeddings if e is not None])}/{len(texts)} th√†nh c√¥ng")
                return embeddings
            else:
                # Sentence Transformer: Encode t·∫•t c·∫£ c√πng l√∫c (nhanh h∆°n)
                logger.info(f"ƒêang t·∫°o embeddings cho {len(texts)} chunks b·∫±ng Sentence Transformer")
                embeddings = self.embedding_model.encode(
                    texts, 
                    convert_to_numpy=True,
                    show_progress_bar=True,  # Hi·ªÉn th·ªã progress bar
                    batch_size=32  # Batch size cho Sentence Transformer
                )
                logger.info(f"ƒê√£ t·∫°o embeddings cho {len(embeddings)} chunks")
                return [emb.astype(np.float32) for emb in embeddings]
        except Exception as e:
            logger.error(f"L·ªói khi t·∫°o embeddings: {str(e)}", exc_info=True)
            return [None] * len(texts)

